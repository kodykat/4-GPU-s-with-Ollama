# 4-GPU-s-with-Ollama
so you have multiple GPU's and want to know how to run them in ollama... I got you.
This is a guide if you need to run a LLM on a cloud or docker. 
